# Week 6: Deep Q-Learning

This week you will extend Q-Learning with linear function approximation to even more complex environments by implementing a Deep Q-Network (DQN).

## Exercises

1. Implement DQN
2. Add Replay Buffer

## Questions

1. Try other architectures (deeper, wider) and record your observations?
2. How important is the batch size when updating the network?
3. How does the replay buffer size affect training speed?
